---
title             : "Comparison of ICCs using IRT and CTT parameters"
shorttitle        : "Comparison of ICCs using IRT and CTT parameters"
author: 
  - name          : "Diego Figueiras"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "Postal address"
    email         : "figueirasd1@montclair.edu"
    role:         # Contributorship roles (e.g., CRediT, https://casrai.org/credit/)
      - Conceptualization
      - Writing - Original Draft Preparation
      - Writing - Review & Editing
  - name          : "John T. Kulas"
    affiliation   : "1"
    role:
      - Writing - Review & Editing

affiliation:
  - id            : "1"
    institution   : "Montclair State University"


authornote: |
  Add complete departmental affiliations for each author here. Each new line herein must be indented, like this line.

  Enter author note here.

abstract: |

  
  <!-- https://tinyurl.com/ybremelq -->
  
keywords          : "keywords"
wordcount         : "X"

bibliography      : ["r-references.bib", "articles.bib"]

floatsintext      : yes
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no

documentclass     : "apa6"
classoption       : "man"
output            : papaja::apa6_pdf
---

```{r setup, include = FALSE}
library("papaja")
library(psych)
library(reticulate)
r_refs("r-references.bib")
```

```{r analysis-preferences}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed, echo=FALSE, warning=FALSE, message=FALSE)
```


# Introduction
Item characteristic curves are very often used by psychometricians to showcase and analyze the attributes of the item on a test or assessment. The x-axis shows a wide range of trait levels (ranging from high to low on the trait), while the y-axis displays probabilities of getting the item correct that range from 0 to 1. Each item has a curve. By looking at it, we can know the likelihood with which respondents of any trait level would answer any item correctly. If the curve is leaning towards the lower end of the trait level, this indicates that it is easy to answer the item correctly. On the contrary, if the curve is leaning towards the higher end of the trait level, this indicates that the item is difficult. If the curve is steep, this indicates high discrimination among respondents; if it is flat, it indicates no discrimination.  

```{r, include=TRUE, fig.cap="Item characteristic curve. X-axis indicates the trait level, and y-axis indicates the probability of getting the item correct.", echo=FALSE, warning=FALSE, message=FALSE, fig.height=4}

data<-read.csv("simulated_data.csv", header=FALSE)
#data$v30<-abs(data$v30-1)
library(mirt)
library(latticeExtra)
pseudob<-abs(qnorm(.5))

ahat<-function(x){
  r<-(((2.71828)^x)-(2.71828)^-x)/(2.71828-(2.71828)^x)
  ((0.51+(0.02*pseudob)+(0.301*pseudob^2))*r)
  
}
pseudoa<-ahat(.3)
c <- 0
#change pseudob in this line for a scale that allows negative numbers
p <- function(x){c + ((1-c)*(1/(1+2.71828^(-1.7*(pseudoa*(x-pseudob))))))}

curve(p, from=-5, to=5, ylim=c(0, 1), main="Item Characteristic Curves", xlab="Level of Trait")
pseudob<-abs(qnorm(.2))
pseudoa<-ahat(.7)
curve(p, lty="longdash", add=TRUE)
arrows(-1.5,0.4,-3,0.4,col="black")
text(-4,0.4, "Low \n Discrimination",col="black")
arrows(0.45,0.2,2,0.2,col="black")
text(3,0.2, "High \n Discrimination",col="black")




```
\newpage
Psychometricians who examine ICCs usually do it using Item Response Theory and Rasch models to get the parameters necessary to plot the curves. In a 2PL model, these would be item difficulty and item discrimination. Item difficulty is the necessary trait level for a respondent to have a 50/50 chance to answer the item correctly. Item discrimination is the degree to which an item can differentiate among individuals with low and high levels of the trait.  From a Classical Test Theory (CTT) frame of thinking, the difficulty of an item is determined by looking at the p-values of the items, while discrimination is determined by checking the Cronbach alpha and the corrected item total correlations. Psychometricians who look at these CTT parameters don’t typically use them to plot ICCs.There is no reason for them not to, since ICCs based on CTT parameters could provide information as valuable as those based on IRT or Rasch without the need of being familiar with these models and with how to compute the necessary estimates. Fan states in summary that IRT and CTT “... framework produce very similar item and person statistics” (p.379).

There is research that shows that there is little difference between the parameters of both frameworks. @lord2012applications described a function that approximates the relationship between IRT and CTT discrimination parameters. Although this wasn't intended for practical purposes but rather to assist in the conceptual comprehension of the discrimination parameter in IRT for people who were more familiar with CTT procedures, the formula was later modified by @kulas2017approximate, with the purpose of minimizing the average residual.The formula is the following:
[INSERT R EXPONENTIAL FORMULA]

Where r is the biserial corrected item total correlation of the item. Simulations identified systematic slope and inflection differences across item with differing b values, so the formula was further changed to include the following modifiers:

[INSERT FINAL FORMULA]
Where g is the absolute deviation from 50% responding an item correctly and 50% responding incorrectly, and it's computed like this: g=|p-0.5|. Zg is the standard normal deviation associated with g. If we visualize the results of these re-specifications of Lord's formula using p-values (difficulty) of .5, .3 (or .7), and .1 (or .9), and corrected item total correlations (discrimination) of .3, .7 and .1, respectively, we get the following:

```{r acorrected, fig.cap="Functional relationship between the IRT *a* parameter and the CTT corrected-item total correlation as a function of item difficulty (p-value; solid = .5, dashed = .3/.7, dotted = .1/.9)."}
g<-abs(qnorm(.5))
g<-0
r2<-.3
ahat<-function(r2){
  r<-(((2.71828)^r2)-(2.71828)^-r2)/(2.71828-(2.71828)^r2)
  ((0.51+(0.02*g)+(0.301*g^2))*r)
 
}

curve(ahat, from=0, to=1, ylim=c(0, 8), xname="Corrected Item-Total Correlation", ylab="IRT a-parameter")
g<-abs(qnorm(.75))
r2<-.7
curve(ahat, lty="longdash",add=TRUE )
g<-abs(qnorm(.1))
r2<-.1
curve(ahat, lty="dotted", add=TRUE)

```

As we can see, the higher the corrected item-total correlations, the higher the estimated IRT a-parameter (discrimination). Also, as the p-values (difficulty) deviates from 0, the relationship between the estimated IRT a-parameter and the corrected item-total correlations becomes stronger. 

Practitioners and researchers that don't use IRT or Rasch models and instead opt to follow a CTT philosophy would benefit from having ICCs that use CTT statistics. This study intends to show evidence of the overlapping nature of CTT and IRT parameters when it comes to plotting ICCs. 

# Study 1 - Visual of discrimination relationship

The purpose of study 1 is to look at the visualizations resulting from @kulas2017approximate formula on simulated data. We hypothesize that the relationship between the estimated IRT a-parameter and the corrected item-total correlations will be stronger as the later deviates from 0, which would mean that the item has more discrimination. 

## Procedure and methods

We simulated data using @han2007wingen3 software. Our sample was 10,000 observations, with a mean of 0 and a standard deviation of 1. The number of itemm were 50, with response categories of either correct or incorrect (1 and 0).



Study 2 simulates a bunch of test data and then we generate ICCs based on the IRT model and then we compare that to our CTT estimates.  
<!-- ## Participants -->

<!-- ## Material -->

<!-- ## Procedure -->

<!-- ## Data analysis -->
<!-- We used `r cite_r("r-references.bib")` for all our analyses. -->





```{r, }
pseudob<-abs(qnorm(.5))

ahat<-function(x){
  r<-(((2.71828)^x)-(2.71828)^-x)/(2.71828-(2.71828)^x)
  ((0.51+(0.02*pseudob)+(0.301*pseudob^2))*r)
  
}
pseudoa<-ahat(.3)
c <- 0
#change pseudob in this line for a scale that allows negative numbers
eq <- function(x){c + ((1-c)*(1/(1+2.71828^(-1.7*(pseudoa*(x-pseudob))))))}

curve(eq, from=-5, to=5, ylim=c(0, 1))
pseudob<-abs(qnorm(.2))
pseudoa<-ahat(.7)
curve(eq, col="red", add=TRUE)

```

```{r,}
data<-read.csv("simulated_data.csv", header=FALSE)
#data$v30<-abs(data$v30-1)
library(mirt)
library(latticeExtra)
model<-"personality=1-30"
data<-data[2:31]
results <- mirt(data=data, model=model, SE= TRUE)
plot(results, type='trace',face_items=FALSE)

mod<-mirt(data, 1, itemtype="2PL")
plot(mod, type="trace", which.items=c(29), facet_items=FALSE)

pseudob<-abs(qnorm(mean(data$v10)))

ahat<-function(x){
  r<-(((2.71828)^x)-(2.71828)^-x)/(2.71828-(2.71828)^x)
  ((0.51+(0.02*pseudob)+(0.301*pseudob^2))*r)
  
}
alpha(data)
pseudoa<-ahat(.63804712)
c <- 0
#pseudob<-pnorm(pseudob)
#change pseudob in this line for a scale that allows negative numbers
eq <- function(x){c + ((1-c)*(1/(1+2.71828^(-1.7*(pseudoa*(x-pseudob))))))}

par(mfrow = c(3, 3))
p1<-plot(mod, which.items=c(29))+latticeExtra::layer(panel.curve(eq, col="red"))
p2<-plot(mod, which.items=c(5))+latticeExtra::layer(panel.curve(eq, col="red"))
p3<-plot(mod, which.items=c(22))+latticeExtra::layer(panel.curve(eq, col="red"))
p4<-plot(mod, which.items=c(8))+latticeExtra::layer(panel.curve(eq, col="red"))
p5<-plot(mod, which.items=c(2))+latticeExtra::layer(panel.curve(eq, col="red"))
p6<-plot(mod, which.items=c(10))+latticeExtra::layer(panel.curve(eq, col="red"))
require(gridExtra)
grid.arrange(p1,p2, p3,p4, ncol=2, nrow=2)

```

```{r,}

pseudob<-abs(qnorm(mean(data$i28)))

ahat<-function(x){
  r<-(((2.71828)^x)-(2.71828)^-x)/(2.71828-(2.71828)^x)
  ((0.51+(0.02*pseudob)+(0.301*pseudob^2))*r)
  
}
alpha(data)
pseudoa<-ahat(.104)
c <- 0
#change pseudob in this line for a scale that allows negative numbers
eq <- function(x){c + ((1-c)*(1/(1+2.71828^(-1.7*(pseudoa*(x-pseudob))))))}

curve(eq, from=-5, to=5, ylim=c(0, 1))



x<-log(.6/(1-.6))
```

# Results

# Discussion


\newpage

# References

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id="refs" custom-style="Bibliography"></div>
\endgroup
