---
title             : "Comparison of ICCs using IRT and CTT parameters"
shorttitle        : "Comparison of ICCs using IRT and CTT parameters"
author: 
  - name          : "Diego Figueiras"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "Postal address"
    email         : "figueirasd1@montclair.edu"
    role:         # Contributorship roles (e.g., CRediT, https://casrai.org/credit/)
      - Conceptualization
      - Writing - Original Draft Preparation
      - Writing - Review & Editing
  - name          : "John T. Kulas"
    affiliation   : "1"
    role:
      - Writing - Review & Editing

affiliation:
  - id            : "1"
    institution   : "Montclair State University"


authornote: |
  Add complete departmental affiliations for each author here. Each new line herein must be indented, like this line.

  Enter author note here.

abstract: |

  
  <!-- https://tinyurl.com/ybremelq -->
  
keywords          : "keywords"
wordcount         : "X"

bibliography      : ["r-references.bib", "articles.bib"]

floatsintext      : yes
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no

documentclass     : "apa6"
classoption       : "man"
output            : papaja::apa6_pdf
---

```{r setup, include = FALSE}
library("papaja")
library(psych)
library(reticulate)
r_refs("r-references.bib")
```

```{r analysis-preferences}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed, echo=FALSE, warning=FALSE, message=FALSE)
```


# Introduction
Item characteristic curves are very often used by psychometricians to showcase and analyze the attributes of the item on a test or assessment. The x-axis shows a wide range of trait levels (ranging from high to low on the trait), while the y-axis displays probabilities of getting the item correct that range from 0 to 1. Each item has a curve. By looking at it, we can know the likelihood with which respondents of any trait level would answer any item correctly. If the curve is leaning towards the lower end of the trait level, this indicates that it is easy to answer the item correctly. On the contrary, if the curve is leaning towards the higher end of the trait level, this indicates that the item is difficult. If the curve is steep, this indicates high discrimination among respondents; if it is flat, it indicates no discrimination.  

```{r, include=TRUE, fig.cap="Item characteristic curve. X-axis indicates the trait level, and y-axis indicates the probability of getting the item correct.", echo=FALSE, warning=FALSE, message=FALSE, fig.height=4}

data<-read.csv("simulated_data.csv", header=FALSE)
#data$v30<-abs(data$v30-1)
library(mirt)
library(latticeExtra)
pseudob<-abs(qnorm(.5))

ahat<-function(x){
  r<-(((2.71828)^x)-(2.71828)^-x)/(2.71828-(2.71828)^x)
  ((0.51+(0.02*pseudob)+(0.301*pseudob^2))*r)
  
}
pseudoa<-ahat(.3)
c <- 0
#change pseudob in this line for a scale that allows negative numbers
p <- function(x){c + ((1-c)*(1/(1+2.71828^(-1.7*(pseudoa*(x-pseudob))))))}

curve(p, from=-5, to=5, ylim=c(0, 1), main="Item Characteristic Curves", xlab="Level of Trait")
pseudob<-abs(qnorm(.2))
pseudoa<-ahat(.7)
curve(p, lty="longdash", add=TRUE)
arrows(-3,0.4,-1.5,0.4,col="black")
text(-4,0.4, "Low \n Discrimination",col="black")
arrows(2,0.2,0.45,0.2,col="black")
text(3,0.2, "High \n Discrimination",col="black")




```
\newpage
Psychometricians who examine ICCs usually do it using Item Response Theory and Rasch models to get the parameters necessary to plot the curves. In a 2PL model, these would be item difficulty and item discrimination. Item difficulty is the necessary trait level for a respondent to have a 50/50 chance to answer the item correctly. Item discrimination is the degree to which an item can differentiate among individuals with low and high levels of the trait.  From a Classical Test Theory (CTT) frame of thinking, the difficulty of an item is determined by looking at the p-values of the items, while discrimination is determined by checking the Cronbach alpha and the corrected item total correlations. Psychometricians who look at these CTT parameters don’t typically use them to plot ICCs.There is no reason for them not to, since ICCs based on CTT parameters could provide information as valuable as those based on IRT or Rasch without the need of being familiar with these models and with how to compute the necessary estimates. Fan states in summary that IRT and CTT “... framework produce very similar item and person statistics” (p.379).

There is research that shows that there is little difference between the parameters of both frameworks.@hambleton1993comparison concluded that "no study provides enough empirical evidence on the extent of disparity between the two frameworks and the superiority of IRT over CTT despite the theoretical differences". 

@fan1998item conducted a study to empirically test the differences between the two frameworks. According to him, "The findings here simply show that the two measurement frameworks produced very similar item and person statistics both in terms of the comparability of item and person statistics between the two frameworks and in terms of the degree of invariance of item statistics from the two competing measurement frameworks." In his study, @fan1998item looked at the correlations between ability estimates and item difficulty in CTT and all three IRT models. These correlations were very high, between high .80 and low .90. As of item discrimination, correlations were moderate to high, with only a few being very low.

He also looked at the item invariance for all models. In theory, the major advantage of IRT models over CTT is that the latter has a circular dependency between the item and person statistics, while IRT has no such dependency, which means that the item parameters don't depend on the sample and the person parameters don't depend on the set of items. This property of invariance is very important, since item estimates can be used regardless of the sample you are giving the test or assessment to. An item will always have the same level of difficulty regardless of who is responding, for example. 

What @fan1998item got on his study, however, shows empirical evidence against this supposed advantage of IRT against CTT. The CTT item difficulty and discrimination degrees of invariance were highly correlated with those of IRT, indicating that they were highly comparable. 


@lord2012applications described a function that approximates the relationship between IRT and CTT discrimination parameters. Although this wasn't intended for practical purposes but rather to assist in the conceptual comprehension of the discrimination parameter in IRT for people who were more familiar with CTT procedures, the formula was later modified by @kulas2017approximate, with the purpose of minimizing the average residual.The formula is the following:
[INSERT R EXPONENTIAL FORMULA]

Where r is the biserial corrected item total correlation of the item. Simulations identified systematic slope and inflection differences across item with differing b values, so the formula was further changed to include the following modifiers:

[INSERT FINAL FORMULA]
Where g is the absolute deviation from 50% responding an item correctly and 50% responding incorrectly, and it's computed like this: g=|p-0.5|. Zg is the standard normal deviation associated with g. If we visualize the results of these re-specifications of Lord's formula using p-values (difficulty) of .5, .3 (or .7), and .1 (or .9), and corrected item total correlations (discrimination) of .3, .7 and .1, respectively, we get the following:

```{r acorrected, fig.cap="Functional relationship between the IRT *a* parameter and the CTT corrected-item total correlation as a function of item difficulty (p-value; solid = .5, dashed = .3/.7, dotted = .1/.9)."}
g<-abs(qnorm(.5))
g<-0
r2<-.3
ahat<-function(r2){
  r<-(((2.71828)^r2)-(2.71828)^-r2)/(2.71828-(2.71828)^r2)
  ((0.51+(0.02*g)+(0.301*g^2))*r)
 
}

curve(ahat, from=0, to=1, ylim=c(0, 8), xname="Corrected Item-Total Correlation", ylab="IRT a-parameter")
g<-abs(qnorm(.75))
r2<-.7
curve(ahat, lty="longdash",add=TRUE )
g<-abs(qnorm(.1))
r2<-.1
curve(ahat, lty="dotted", add=TRUE)

```

As we can see, the higher the corrected item-total correlations, the higher the estimated IRT a-parameter (discrimination). Also, as the p-values (difficulty) deviates from 0, the relationship between the estimated IRT a-parameter and the corrected item-total correlations becomes stronger. 

Practitioners and researchers that don't use IRT or Rasch models and instead opt to follow a CTT philosophy would benefit from having ICCs that use CTT statistics. This study intends to show evidence of the overlapping nature of CTT and IRT parameters when it comes to plotting ICCs. 

# Study 1 - Visual of discrimination relationship

The purpose of study 1 is to look at the visualizations resulting from @kulas2017approximate formula on simulated data. We hypothesize that the relationship between the estimated IRT a-parameter and the corrected item-total correlations will be stronger as the later deviates from 0, which would mean that the item has more discrimination. 

## Procedure and methods

We simulated data using @han2007wingen3 software. Our sample was 10,000 observations, with a mean of 0 and a standard deviation of 1. The number of items were 100, with response categories of either correct or incorrect (1 and 0).The mean for the a parameter was 2, and the standard deviation 0.8. The mean for parameter b was 0 and the standard deviation 0.5. 

## Results

```{r acorrected simulation, fig.cap="Functional relationship between the IRT *a* parameter and the CTT corrected-item total correlation as a function of item difficulty (p-value; solid = .3, dashed = .9, dotted = .12)."}
data<-read.csv("simulated_data.csv", header=FALSE)
g<-abs(qnorm(mean(data$V50)))
r2<-.552939712
ahat<-function(r2){
  r<-(((2.71828)^r2)-(2.71828)^-r2)/(2.71828-(2.71828)^r2)
  ((0.51+(0.02*g)+(0.301*g^2))*r)
 
}

curve(ahat, from=0, to=1, ylim=c(0, 8), xname="Corrected Item-Total Correlation", ylab="IRT a-parameter")
g<-abs(qnorm(mean(data$V47)))
r2<-.173791903
curve(ahat, lty="longdash",add=TRUE )
g<-abs(qnorm(mean(data$V2)))
r2<-.315436055
curve(ahat, lty="dotted", add=TRUE)

```
\newpage


# Study 2 - Item Characteristic Curves comparisons. 

The purpose of study 2 is to simulates a lot of test data and then generate ICCs based on the IRT model and then we compare that to our CTT estimates.  

## Procedure and materials
The same simulated data as in study 1 was used. The mirt package was used to compute the IRT statistics. The blue curves were plotted using 2PL IRT parameters (a and b), while the red curves were plotted using CTT parameters (p-values and corrected item-total correlations, modifying them with @kulas2017approximate formulas). 

## Results
We calculated the area between the curves plotted using CTT parameters and the curves with IRT parameters. The average difference for all 100 curves was 0.35. 
<!-- ## Participants -->

<!-- ## Material -->

<!-- ## Procedure -->

<!-- ## Data analysis -->
<!-- We used `r cite_r("r-references.bib")` for all our analyses. -->




```{r, plotting, results="hide" }

data<-read.csv("simulated_data.csv", header=FALSE)
#data$v30<-abs(data$v30-1)
library(mirt)
library(latticeExtra)
library(irtplay)
ahat<-function(x){
  r<-(((2.71828)^x)-(1/(2.71828)^x))/(2.71828-(2.71828)^x)
  
  ((0.51+(0.02*pseudob)+(0.301*pseudob^2))*r)+((0.57-(0.009*pseudob)+(0.19*pseudob^2))*r)
  
}

mod<-mirt(data, 1, itemtype="2PL")
# plot(mod, type="trace")
# 
alphas<-alpha(data)
citcs<-data.frame(alphas$item.stats$r.drop)
pseudoA<-data.frame(ahat(citcs))
pseudoB<-data.frame(qnorm(colMeans(data)))
IRT_parms <- coef(mod, IRTpars = TRUE, simplify = TRUE)
irt <- IRT_parms$items
df<-as.data.frame(cbind(citcs, pseudoA, pseudoB, irt))
colnames(df)<-c("CITC", "PseudoA", "PseudoB", "a", "b", "c1", "c2")

# plot(df$PseudoA, df$a)
# plot(df$b, df$PseudoB)

lm.reg<-lm(b ~., data=df)
 

b<-0.01479-(-1.33142*pseudoB) 
dat<-data.frame(b, alphas$item.stats$r.drop)
colnames(dat)<-c("b", "corrected item totals")
###############################################################
pseudob<-dat$b[47]
ahat<-function(x){
  r<-(((2.71828)^x)-(1/(2.71828)^x))/(2.71828-(2.71828)^x)
  
  ((0.51+(0.02*pseudob)+(0.301*pseudob^2))*r)+((0.57-(0.009*pseudob)+(0.19*pseudob^2))*r)
  
}

pseudoa<-ahat(dat$`corrected item totals`[47])
c <- 0

eq <- function(x){c + ((1-c)*(1/(1+2.71828^(-1.7*(pseudoa*(x-pseudob))))))}

p1<-plot(mod, which.items=c(47), main=FALSE, sub="Medium area between curves (0.36 )")+latticeExtra::layer(panel.curve(eq, col="red"))
################################################################

pseudob2<-dat$b[1]
ahat<-function(x){
  r<-(((2.71828)^x)-(1/(2.71828)^x))/(2.71828-(2.71828)^x)
  
  ((0.51+(0.02*pseudob2)+(0.301*pseudob2^2))*r)+((0.57-(0.009*pseudob2)+(0.19*pseudob2^2))*r)
  
}

pseudoa2<-ahat(dat$`corrected item totals`[1])
c <- 0

eq2 <- function(x){c + ((1-c)*(1/(1+2.71828^(-1.7*(pseudoa2*(x-pseudob2))))))}

p2<-plot(mod, which.items=c(1),main=FALSE, sub="Low area between curves (0.03)")+latticeExtra::layer(panel.curve(eq2, col="red"))


#####################################################################

pseudob3<-dat$b[54]
ahat<-function(x){
  r<-(((2.71828)^x)-(1/(2.71828)^x))/(2.71828-(2.71828)^x)
  
  ((0.51+(0.02*pseudob3)+(0.301*pseudob3^2))*r)+((0.57-(0.009*pseudob3)+(0.19*pseudob3^2))*r)
  
}

pseudoa3<-ahat(dat$`corrected item totals`[54])
c <- 0

eq3 <- function(x){c + ((1-c)*(1/(1+2.71828^(-1.7*(pseudoa3*(x-pseudob3))))))}

p3<-plot(mod, which.items=c(54), main=FALSE, sub="Low area between curves (0.09)")+latticeExtra::layer(panel.curve(eq3, col="red"))

###############################################################################
pseudob4<- dat$b[25]
ahat<-function(x){
  r<-(((2.71828)^x)-(1/(2.71828)^x))/(2.71828-(2.71828)^x)
  
  ((0.51+(0.02*pseudob4)+(0.301*pseudob4^2))*r)+((0.57-(0.009*pseudob4)+(0.19*pseudob4^2))*r)
  
}

pseudoa4<-ahat(dat$`corrected item totals`[25])
c <- 0

eq4 <- function(x){c + ((1-c)*(1/(1+2.71828^(-1.7*(pseudoa4*(x-pseudob4))))))}

p4<-plot(mod, which.items=c(25), main=FALSE, sub="Big area between curves (0.81)")+latticeExtra::layer(panel.curve(eq4, col="red"))

###############################################################################
require(gridExtra)
grid.arrange(p1,p2,p3,p4, top="Item Characteristic Curves",nrow=2, ncol=2)

##############################################################################



```

```{r, AUC, results="hide",fig.cap="ICCs using CTT parameters"}
#Area between curves
#Preparing data
library(geiger)
citcs<-data.frame(alphas$item.stats$r.drop)
pseudoA<-data.frame(ahat(citcs))
pseudoB<-b
IRT_parms <- coef(mod, IRTpars = TRUE, simplify = TRUE)
irt <- IRT_parms$items
df<-as.data.frame(cbind(citcs, pseudoA, pseudoB, irt))
colnames(df)<-c("CITC", "PseudoA", "PseudoB", "a", "b", "c1", "c2")

#calculating AUC
theta <- matrix(seq(-6,6, by=.1))
# eq4 <- function(x){c + ((1-c)*(1/(1+2.71828^(-1.7*(df$PseudoA[25]*(x-df$PseudoB[25]))))))}
# cttB<-eq4(seq(-6,6, by=.1))
# eq4_irt<-function(x){c + ((1-c)*(1/(1+2.71828^(-1.7*(df$a[25]*(x-df$b[25]))))))}
# irtB<-eq4_irt(seq(-6,6, by=.1))
# geiger:::.area.between.curves(theta, cttB, irtB)
# x is the vector of x-axis values
# f1 the y-axis values for the first line
# f2 the y-axis values for the second line

#Looping
auc<-rep(NA, nrow(df))
p_ctt<-0
p_irt<-0
colors<-rep(c("Red", "blue","yellow","orange","purple","brown","green","pink","black", "white"), 10)
eq_CTT<- function(x){c + ((1-c)*(1/(1+2.71828^(-1.7*(df$PseudoA[1]*(x-df$PseudoB[1]))))))}
p_ctt<-curve(eq_CTT, xlim=c(-4,4))
for (i in 1:nrow(df)){
  eq_CTT<- function(x){c + ((1-c)*(1/(1+2.71828^(-1.7*(df$PseudoA[i]*(x-df$PseudoB[i]))))))}
  p_ctt[i]<-curve(eq_CTT, col=colors[i], xlim=c(-4,4), add=TRUE)
  
  cttB<-eq_CTT(seq(-6,6, by=.1))
  eq_IRT<-function(x){c + ((1-c)*(1/(1+2.71828^(-1.7*(df$a[i]*(x-df$b[i]))))))}
  irtB<-eq_IRT(seq(-6,6, by=.1))
  auc[i]<-abs(geiger:::.area.between.curves(theta, cttB, irtB))
}
p_ctt
arrows(3.2,0.85,2.2,0.85,col="purple")
text(3.5,0.85, "Item 4",col="purple")
arrows(2,0.4,1.5,0.4,col="black")
text(2.5,0.4, "Item 24",col="black")

```

```{r irt curves, results="hide",fig.cap="ICCs using IRT parameters"}
eq_IRT<-function(x){c + ((1-c)*(1/(1+2.71828^(-1.7*(df$a[1]*(x-df$b[1]))))))}
p_irt<-curve(eq_IRT, xlim=c(-4,4))

for (i in 1:nrow(df)){
    eq_IRT<-function(x){c + ((1-c)*(1/(1+2.71828^(-1.7*(df$a[i]*(x-df$b[i]))))))}
    p_irt[i]<-curve(eq_IRT, col=colors[i], xlim=c(-4,4), add=TRUE)
}

p_irt
arrows(3,0.8,2,0.8,col="purple")
text(3.5,0.8, "Item 4",col="purple")
arrows(2,0.4,1.5,0.4,col="black")
text(2.5,0.4, "Item 24",col="black")
```

# Results

# Discussion


\newpage

# References

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id="refs" custom-style="Bibliography"></div>
\endgroup
